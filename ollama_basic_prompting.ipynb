{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an obedient assistant that fulfills text-based requests and answers questions.\n",
      "You always use the first person or impersonal tone and never use the second person in your responses.\n",
      "1. If available, use the context to answer the question at the end.\n",
      "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\n",
      "3. Keep the answer concise and specific.\n",
      "Context: Baby don't hurt me.\n",
      "Prompt: What is love?\n",
      "Answer:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Thinking... Okay, so I need to figure out what love means based on the context provided. The user mentioned that\n",
      "babies shouldn't hurt others, which probably relates to how people perceive love in different\n",
      "contexts.  I remember hearing that in some cultures, love can be seen as a soft and nurturing kind\n",
      "of feeling. Maybe it's about affectionate or caring aspects. But I also think there are other\n",
      "meanings, especially considering the \"don't hurt\" line. If someone is loved and you hurt them, that\n",
      "might mean they're not truly in your heart.  I should consider both positive and negative\n",
      "interpretations. On one hand, loving others can feel comforting and nurturing. On the other hand,\n",
      "it's also important to respect boundaries and avoid harming others. So love isn't just about caring\n",
      "for yourself but also being mindful of others' feelings and needs.\n",
      "\n",
      " Response:\n",
      " Love is a complex concept that varies across cultures, often involving affectionate or caring\n",
      "aspects. It can mean softness or nurturing, but if someone hurts you, it might indicate they're not\n",
      "truly in your heart.  Answer: Love isn't just about care for yourself; it also involves considering\n",
      "others' feelings and boundaries.\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# Define the prompt\n",
    "pre_prompt = \"\"\"\n",
    "You are an obedient assistant that fulfills text-based requests and answers questions.\n",
    "You always use the first person or impersonal tone and never use the second person in your responses.\n",
    "1. If available, use the context to answer the question at the end.\n",
    "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\n",
    "3. Keep the answer concise and specific.\n",
    "Context: {context}\n",
    "Prompt: {prompt}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(pre_prompt)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=QA_CHAIN_PROMPT,\n",
    "    callbacks=None,\n",
    "    verbose=True)\n",
    "\n",
    "context = \"Baby don't hurt me.\"\n",
    "prompt = \"What is love?\"\n",
    "response = llm_chain.run(context=context, prompt=prompt)\n",
    "\n",
    "think_part = response[response.find(\"<think>\")+7:response.find(\"</think>\")].strip()\n",
    "answer_part = response[response.find(\"</think>\")+8:].strip()\n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=100)\n",
    "wrapped_thought = wrapper.fill(think_part)\n",
    "wrapped_response = wrapper.fill(answer_part)\n",
    "print(f\"Thinking... {wrapped_thought}\\n\\n Response:\\n {wrapped_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run deepseek_chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_28308\\3723357065.py:12: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_28308\\3723357065.py:25: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm_chain.run(prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an useful assistant that fulfills text-based requests and answers questions.\n",
      "Prompt: \n",
      "Joe's mum has four children. The first is called April, the second is called May, and the third is called June. \n",
      "What is the name of the fourth child?\n",
      "\n",
      "Answer:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Thinking... Alright, so I'm trying to figure out the answer to this question. Let me break it down step by step.  First, the question says: \"Joe's mum has four\n",
      "children. The first is called April, the second is called May, and the third is called June. What is the name of the fourth child?\"  Okay, so the\n",
      "mother has four kids. Each kid is given a name starting with A, M, J, and then we're to find out what comes next.  April starts with A, May with M,\n",
      "June with J. So after June, it should logically be August, which also starts with A. Let me double-check that: April (A), May (M), June (J), so the\n",
      "next would be August (A).  Wait a secondâ€”hold on, isn't there an 8th month? Yeah, August is the eighth month of the year. So following A, M, J would\n",
      "be A again for the fourth child.  Is there any chance that the names could have different sounds or something else? Hmm, no, each name seems\n",
      "straightforward. The pattern is A-M-J-A, so logically August makes sense as the next one.  I think I'm confident enough now to say that the fourth\n",
      "child is called August.\n",
      "\n",
      " Response:\n",
      " The fourth child's name is **August**.\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# Define the prompt\n",
    "pre_prompt = \"\"\"\n",
    "You are an useful assistant that fulfills text-based requests and answers questions.\n",
    "Prompt: {prompt}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(pre_prompt)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=QA_CHAIN_PROMPT,\n",
    "    callbacks=None,\n",
    "    verbose=True)\n",
    "\n",
    "# prompt = \"Who is the health minister in Spain?\" # The model doesn't know\n",
    "# Riddle\n",
    "prompt = \"\"\"\n",
    "Joe's mum has four children. The first is called April, the second is called May, and the third is called June. \n",
    "What is the name of the fourth child?\n",
    "\"\"\"\n",
    "\n",
    "response = llm_chain.run(prompt=prompt)\n",
    "\n",
    "think_part = response[response.find(\"<think>\")+7:response.find(\"</think>\")].strip()\n",
    "answer_part = response[response.find(\"</think>\")+8:].strip()\n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=150)\n",
    "wrapped_thought = wrapper.fill(think_part)\n",
    "wrapped_response = wrapper.fill(answer_part)\n",
    "print(f\"Thinking... {wrapped_thought}\\n\\n Response:\\n {wrapped_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
